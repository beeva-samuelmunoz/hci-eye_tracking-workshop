{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib import keras\n",
    "\n",
    "from smh_eyetracking.features02 import config as config_features02\n",
    "from smh_eyetracking.features02.utils.features02_dlib import FACE, JAWLINE, NOSE, LEFT_EYE, RIGHT_EYE, TARGETS\n",
    "from smh_eyetracking.keras import config as config_keras\n",
    "from smh_eyetracking.keras import losses\n",
    "from smh_eyetracking.utils import data_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = data_model.load(\n",
    "    config_features02.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_CSV,\n",
    "    config_features02.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_IMGS_LEFT,\n",
    "    config_features02.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = data_model.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    validation_size=0.15,\n",
    "    test_size=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = config_features02.FEATURES02_EYES_SIZE\n",
    "img_shape = (img_height, img_width)\n",
    "\n",
    "def eye_prediction(imgs, eye_features, other_features):\n",
    "    c1 = keras.layers.Conv2D(\n",
    "        filters=6,\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        padding=\"valid\",\n",
    "        activation='relu'\n",
    "    )(keras.layers.Reshape((24,32,1))(imgs))\n",
    "    # TODO 6 trainable coefficients  and 6 trainnable bias\n",
    "    s2 = keras.layers.AveragePooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=None,  # Same as pool_size\n",
    "        padding='valid'\n",
    "    )(c1)\n",
    "    c3 = keras.layers.Conv2D(\n",
    "        filters=16,\n",
    "        kernel_size=(3,3),\n",
    "        strides=(1,1),\n",
    "        padding=\"valid\",\n",
    "        activation='relu'\n",
    "    )(s2)\n",
    "    s4 = keras.layers.AveragePooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=None,  # Same as pool_size\n",
    "        padding='valid'\n",
    "    )(c3)\n",
    "    f5 = keras.layers.Dense(128, activation=\"relu\")(keras.layers.Flatten()(s4))\n",
    "    f6 = keras.layers.Dense(64, activation=\"relu\")(f5)\n",
    "    c7 = keras.layers.Concatenate()([f6,eye_features])\n",
    "    f8 = keras.layers.Dense(32, activation=\"relu\")(c7)\n",
    "    f9 = keras.layers.Dense(8, activation=\"relu\")(f8)\n",
    "    #out = keras.layers.Dense(1)(f9)\n",
    "    return f9\n",
    "    \n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # Inputs\n",
    "    left_imgs = keras.layers.Input(shape=img_shape, name='left_imgs', dtype='float32')\n",
    "    right_imgs = keras.layers.Input(shape=img_shape, name='right_imgs', dtype='float32')\n",
    "    \n",
    "    features_jawline = keras.layers.Input(shape=(len(JAWLINE),), name='features_jawline', dtype='float32')\n",
    "    features_nose = keras.layers.Input(shape=(len(NOSE),), name='features_nose', dtype='float32')\n",
    "    features_left_eye = keras.layers.Input(shape=(len(LEFT_EYE),), name='features_left_eye', dtype='float32')\n",
    "    features_right_eye = keras.layers.Input(shape=(len(RIGHT_EYE),), name='features_right_eye', dtype='float32')\n",
    "    features_face = keras.layers.Input(shape=(len(FACE),), name='features_face', dtype='float32')\n",
    "    \n",
    "    other_features = keras.layers.Concatenate()([features_jawline, features_nose, features_face])\n",
    "    \n",
    "    extra_x_01 = keras.layers.Dense(32, activation=\"relu\")(other_features)\n",
    "    extra_x_02 = keras.layers.Dense(8, activation=\"relu\")(extra_x_01)\n",
    "    #extra_x = keras.layers.Dense(1, activation=\"relu\")(extra_x_02)\n",
    "    eye_predictions_x = keras.layers.Dense(1, activation=\"linear\")(keras.layers.Concatenate()([\n",
    "        eye_prediction(left_imgs, features_left_eye, other_features),\n",
    "        eye_prediction(right_imgs, features_right_eye, other_features),\n",
    "        extra_x_02\n",
    "    ]))\n",
    "    \n",
    "    extra_y_01 = keras.layers.Dense(32, activation=\"relu\")(other_features)\n",
    "    extra_y_02 = keras.layers.Dense(8, activation=\"relu\")(extra_y_01)\n",
    "    #extra_y = keras.layers.Dense(1, activation=\"relu\")(extra_y_02)\n",
    "    eye_predictions_y = keras.layers.Dense(1, activation=\"linear\")(keras.layers.Concatenate()([\n",
    "        eye_prediction(left_imgs, features_left_eye, other_features),\n",
    "        eye_prediction(right_imgs, features_right_eye, other_features),\n",
    "        extra_y_02\n",
    "    ]))\n",
    "    \n",
    "    eye_predictions = keras.layers.Concatenate()([eye_predictions_x,eye_predictions_y])\n",
    "   \n",
    "    # Model\n",
    "    model = keras.models.Model(\n",
    "        inputs=[\n",
    "            left_imgs, right_imgs,\n",
    "            features_jawline, features_nose, features_left_eye, features_right_eye, features_face\n",
    "        ],\n",
    "        outputs=[eye_predictions]\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '05_lenet5-01'\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0005\n",
    "DECAY = 0.00001\n",
    "DROPOUT = 0\n",
    "\n",
    "LOSS = losses.mean_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=LOSS,\n",
    "    metrics=[losses.mean_euclidean],\n",
    "    optimizer=keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=DECAY)\n",
    ")\n",
    "\n",
    "print(\"Parameters to adjust: {}\".format(\n",
    "    np.sum([keras.backend.count_params(p) for p in set(model.trainable_weights)])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x={\n",
    "        'left_imgs':train_imgs_left,\n",
    "        'right_imgs': train_imgs_right,\n",
    "        'features_jawline': train_data[JAWLINE].as_matrix(),\n",
    "        'features_nose': train_data[NOSE].as_matrix(),\n",
    "        'features_left_eye': train_data[LEFT_EYE].as_matrix(),\n",
    "        'features_right_eye': train_data[RIGHT_EYE].as_matrix(),\n",
    "        'features_face': train_data[FACE].as_matrix()\n",
    "    },\n",
    "    y=train_data[TARGETS].as_matrix(),\n",
    "    validation_data=(\n",
    "        {\n",
    "            'left_imgs': validation_imgs_left,\n",
    "            'right_imgs': validation_imgs_right,\n",
    "            'features_jawline': validation_data[JAWLINE].as_matrix(),\n",
    "            'features_nose': validation_data[NOSE].as_matrix(),\n",
    "            'features_left_eye': validation_data[LEFT_EYE].as_matrix(),\n",
    "            'features_right_eye': validation_data[RIGHT_EYE].as_matrix(),\n",
    "            'features_face': validation_data[FACE].as_matrix()\n",
    "        },\n",
    "        validation_data[TARGETS].as_matrix()\n",
    "    ),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1, callbacks=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(config_keras.PATH_MODELS_KERAS+MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = keras.models.load_model(\n",
    "    filepath=config_keras.PATH_MODELS_KERAS+MODEL_NAME,\n",
    "    custom_objects={\n",
    "        \"mean_euclidean\": losses.mean_euclidean,\n",
    "        \"ms_euclidean\": losses.ms_euclidean,\n",
    "        \"reg_mean_euclidean\": losses.reg_mean_euclidean\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    x={\n",
    "        'left_imgs':test_imgs_left,\n",
    "        'right_imgs': test_imgs_right,\n",
    "        'features_jawline': test_data[JAWLINE].as_matrix(),\n",
    "        'features_nose': test_data[NOSE].as_matrix(),\n",
    "        'features_left_eye': test_data[LEFT_EYE].as_matrix(),\n",
    "        'features_right_eye': test_data[RIGHT_EYE].as_matrix(),\n",
    "        'features_face': test_data[FACE].as_matrix()\n",
    "    },\n",
    "    y=test_data[TARGETS].as_matrix(),\n",
    "    batch_size=1,\n",
    "    verbose=1, sample_weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Corrected dataset\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate | Decay | Loss | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| 05_lenet5-01 | 50 | 64| 0.0005 | 0.00001 | mean_euclidean |  |  |  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
