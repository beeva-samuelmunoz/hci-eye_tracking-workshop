{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_03 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib import keras\n",
    "\n",
    "from smh_eyetracking.features02 import config as config_features02\n",
    "from smh_eyetracking.features02.utils.features02_dlib import FEATURES, TARGETS\n",
    "from smh_eyetracking.keras import config as config_keras\n",
    "from smh_eyetracking.keras import losses\n",
    "from smh_eyetracking.utils import data_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = data_model.load(\n",
    "    config_features02.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_CSV,\n",
    "    config_features02.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_IMGS_LEFT,\n",
    "    config_features02.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = data_model.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    validation_size=0.15,\n",
    "    test_size=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = config_features02.FEATURES02_EYES_SIZE\n",
    "img_shape = (img_height, img_width)\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # Inputs\n",
    "    left_imgs = keras.layers.Input(shape=img_shape, name='left_imgs', dtype='float32')\n",
    "    right_imgs = keras.layers.Input(shape=img_shape, name='right_imgs', dtype='float32')\n",
    "    features = keras.layers.Input(shape=(len(FEATURES),), name='features', dtype='float32')\n",
    "    # Features\n",
    "    f1 = keras.layers.Dense(256, activation=keras.activations.relu)(features)\n",
    "    f2 = keras.layers.Dense(128, activation=keras.activations.relu)(f1)\n",
    "    # Left imgs\n",
    "    l1 = keras.layers.Conv2D(32, (3, 3), (2,2), activation='relu', padding='same')(\n",
    "        keras.layers.Reshape((24,32,1))(left_imgs)\n",
    "    )\n",
    "    l2 = keras.layers.Conv2D(64, (3, 3), (2,2), activation='relu', padding='same')(l1)\n",
    "    # Right imgs\n",
    "    r1 = keras.layers.Conv2D(32, (3, 3), (2,2), activation='relu', padding='same')(\n",
    "        keras.layers.Reshape((24,32,1))(right_imgs)\n",
    "    )\n",
    "    r2 = keras.layers.Conv2D(64, (3, 3), (2,2), activation='relu', padding='same', input_shape=(24, 32, 1))(r1)\n",
    "    # Concatenate\n",
    "    concat = keras.layers.Concatenate()([\n",
    "        keras.layers.Flatten()(l2),\n",
    "        keras.layers.Flatten()(r2),\n",
    "        f2\n",
    "    ])\n",
    "    # Dense\n",
    "    d_1 = keras.layers.Dense(256, activation=keras.activations.relu)(concat)\n",
    "    d_2 = keras.layers.Dense(128, activation=keras.activations.relu)(d_1)\n",
    "    d_3 = keras.layers.Dense(32, activation=keras.activations.relu)(d_2)\n",
    "    d_4 = keras.layers.Dense(2)(d_3)\n",
    "    # Model\n",
    "    model = keras.models.Model(\n",
    "        inputs=[left_imgs, right_imgs, features],\n",
    "        outputs=[d_4]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '03_CNN-09'\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.00001\n",
    "DECAY = 0.000001\n",
    "\n",
    "\n",
    "LOSS = losses.mean_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters to adjust: 1734242\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=LOSS,\n",
    "    metrics=[losses.mean_euclidean],\n",
    "    optimizer=keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=DECAY)\n",
    ")\n",
    "\n",
    "print(\"Parameters to adjust: {}\".format(\n",
    "    np.sum([keras.backend.count_params(p) for p in set(model.trainable_weights)])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x={\n",
    "        'left_imgs':train_imgs_left,\n",
    "        'right_imgs': train_imgs_right,\n",
    "        'features': train_data[FEATURES].as_matrix()\n",
    "    },\n",
    "    y=train_data[TARGETS].as_matrix(),\n",
    "    validation_data=(\n",
    "        {\n",
    "            'left_imgs': validation_imgs_left,\n",
    "            'right_imgs': validation_imgs_right,\n",
    "            'features': validation_data[FEATURES].as_matrix()\n",
    "        },\n",
    "        validation_data[TARGETS].as_matrix()\n",
    "    ),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1, callbacks=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(config_keras.PATH_MODELS_KERAS+MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = keras.models.load_model(\n",
    "    filepath=config_keras.PATH_MODELS_KERAS+MODEL_NAME,\n",
    "    custom_objects={\n",
    "        \"mean_euclidean\": losses.mean_euclidean,\n",
    "        \"ms_euclidean\": losses.ms_euclidean,\n",
    "        \"reg_mean_euclidean\": losses.reg_mean_euclidean\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_test.evaluate(\n",
    "    x={\n",
    "        'left_imgs':test_imgs_left,\n",
    "        'right_imgs': test_imgs_right,\n",
    "        'features': test_data[FEATURES].as_matrix()\n",
    "    },\n",
    "    y=test_data[TARGETS].as_matrix(),\n",
    "    batch_size=1,\n",
    "    verbose=1, sample_weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Corrected dataset\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate | Decay | Loss | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| 03_CNN-01 | 50 | 128| 0.005 | 0.0001 | mean_euclidean | 0.1385 | 0.2369 | 0.2481 |\n",
    "| 03_CNN-02 | 50 | 128| 0.0005 | 0.00001 | mean_euclidean | 0.0394 | 0.1696 | 0.1768 |\n",
    "| 03_CNN-03 | 117 (stopped) | 128| 0.0005 | 0.00001 | mean_euclidean | 0.0232 | 0.1705 | 0.1771 |\n",
    "| 03_CNN-04 | 50 | 128 | 0.00005 | 0.000001 | mean_euclidean | 0.0861 | 0.1644 | 0.1801 |\n",
    "| 03_CNN-05 | 50 | 64 | 0.00005 | 0.000001 | mean_euclidean | 0.0565 | 0.1586 | 0.1742 |\n",
    "| 03_CNN-06 | 50 | 32 | 0.00005 | 0.000001 | mean_euclidean | 0.0441 | 0.1670 | 0.1808 |\n",
    "| 03_CNN-07 | 50 | 64 | 0.000005 | 0.000001 | mean_euclidean | 0.1824 | 0.1902 | 0.1979 |\n",
    "| 03_CNN-08 | 100 | 64 | 0.000005 | 0.000001 | mean_euclidean | 0.1411 | 0.1745 | 0.1892 |\n",
    "| 03_CNN-09 | 50 | 64 | 0.00001 | 0.000001 | mean_euclidean | 0.1342 | 0.1742 | 0.1910 |\n",
    "| 03_CNN-10 | 100 | 64 | 0.00001 | 0.000001 | mean_euclidean | 0.0935 | 0.1658 | 0.1781 |\n",
    "| 03_CNN-11 | 150 | 64 | 0.00001 | 0.000001 | mean_euclidean | 0.0702 | 0.1647 | 0.1746 |\n",
    "| 03_CNN-12 | 200 | 64 | 0.00001 | 0.000001 | mean_euclidean | 0.0554 | 0.1658 | 0.1747 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
